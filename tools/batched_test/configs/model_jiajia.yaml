- name: "example-model"
  model_path: "/path/to/example-model"
  timeout: 600 # default is 600 seconds
  serve_config:
    tp: 99
    pp: 99
    dp: 99
    distributed_executor_backend: "ray"  # default
    gpu_memory_utilization: 0.9  # default
    swap_space: 16  # default
    max_model_len: 4096  # default

    # Optional extra arguments for vllm serve command
    # won't overwrite the default args
    # won't check the validity of these args
    extra_args:
      -mtp:
      --chat-template: "/relative/path/to/scheduler.py"
  infer_type: # one of the following types (required)
    - text-only  # supported
    - single-image # supported
    - multi-image # TODO(hank): not supported yet
    - multi-modal # TODO(hank): not supported yet
    - video # TODO(hank): not supported yet
    - audio # TODO(hank): not supported yet
  benchmark:
      bench_param: "/relative/path/to/scheduler.py" # default
      dataset_name: "random"  # default
      ignore_eos: true  # default
      sweep_num_runs: 3  # default
  extra_env:
    EXAMPLE_ENV_VAR: "value"


# - name: "DeepSeek-V2-Lite"
#   model_path: "/mnt/share/models/DeepSeek/DeepSeek-V2-Lite"
#   serve_config:
#     tp: 1
#     pp: 1
#     dp: 1
#     extra_args:
#   infer_type:
#     - text-only
#   benchmark:
#     bench_param: "configs/bench_params/bench_2.json"
#     sweep_num_runs: 1
#   extra_env:
#     MACA_QUEUE_SCHEDULE_POLICY: 1

# - name: "Qwen3-30B-A3B"
#   model_path: "/mnt/share/models/Qwen/Qwen3-30B-A3B"
#   serve_config:
#     tp: 2
#     pp: 1
#     dp: 1
#     extra_args:
#   infer_type:
#     - text-only
#   benchmark:
#     bench_param: "configs/bench_params/bench_2.json"
#     sweep_num_runs: 1
#   extra_env:

# - name: "Qwen3-4B"
#   model_path: "/mnt/share/models/Qwen/Qwen3-4B"
#   serve_config:
#     tp: 1
#     pp: 1
#     dp: 1
#     extra_args:
#   infer_type:
#     - text-only
#   benchmark:
#     bench_param: "configs/bench_params/bench_2.json"
#     sweep_num_runs: 1
#   extra_env:

# - name: "Qwen3-VL-8B-Instruct"
#   model_path: "/mnt/share/models/Qwen/Qwen3-VL-8B-Instruct"
#   serve_config:
#     tp: 1
#     pp: 1
#     dp: 1
#     max_model_len: 40960  # default
#     extra_args:
#   infer_type:
#     - single-image
#   benchmark:
#     bench_param: "configs/bench_params/bench_2.json"
#     sweep_num_runs: 1
#   extra_env:


# - name: "Qwen3-8B"
#   model_path: "/mnt/share/models/Qwen/Qwen3-8B"
#   serve_config:
#     tp: 1
#     pp: 1
#     dp: 1
#     extra_args:
#   infer_type:
#     - text-only
#   benchmark:
#     bench_param: "configs/bench_params/bench_2.json"
#     sweep_num_runs: 1
#   extra_env:


# - name: "Qwen3-Next-80B-A3B-Instruct"
#   model_path: "/mnt/share/models/Qwen/Qwen3-Next-80B-A3B-Instruct"
#   serve_config:
#     tp: 4
#     pp: 1
#     dp: 1
#     extra_args:
#   infer_type:
#     - text-only
#   benchmark:
#     bench_param: "configs/bench_params/bench_2.json"
#     sweep_num_runs: 1
#   extra_env:


# - name: "Qwen3-30B-A3B-W8A8"
#   model_path: "/mnt/share/models/Qwen/Qwen3-30B-A3B_w8a8"
#   serve_config:
#     tp: 1
#     pp: 1
#     dp: 1
#     extra_args:
#   infer_type:
#     - text-only
#   benchmark:
#     bench_param: "configs/bench_params/bench_2.json"
#     sweep_num_runs: 1
#   extra_env:


- name: "Qwen3-235B-A22B-W8A8"
  model_path: "/mnt/share/models/Qwen/Qwen3-235B-A22B_w8a8"
  timeout: 1200
  serve_config:
    tp: 8
    pp: 1
    dp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_2.json"
    sweep_num_runs: 1
  extra_env:
