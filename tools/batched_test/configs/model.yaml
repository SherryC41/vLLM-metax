- name: "DeepSeek-R1-Distill-Llama-8B"
  model_path: "/mxstorage/pde_ai/models/llm/DeepSeek/DeepSeek-R1-Distill-Llama-8B"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "DeepSeek-OCR"
  model_path: "/mxstorage/pde_ai/models/llm/DeepSeek/DeepSeek-OCR"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:


- name: "DeepSeek-R1-Distill-Qwen-7B"
  model_path: "/mxstorage/pde_ai/models/llm/DeepSeek/DeepSeek-R1-Distill-Qwen-7B"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:


- name: "DeepSeek-R1-Distill-Qwen-14B"
  model_path: "/mxstorage/pde_ai/models/llm/DeepSeek/DeepSeek-R1-Distill-Qwen-14B"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:


- name: "DeepSeek-V2-Lite"
  model_path: "/mxstorage/pde_ai/models/llm/DeepSeek/DeepSeek-V2-Lite"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:
    MACA_QUEUE_SCHEDULE_POLICY: 1

- name: "DeepSeek-R1-BF16-L4-W8A8"
  model_path: "/mxstorage/pde_ai/models/llm/DeepSeek/DeepSeek-R1-BF16-L4-W8A8"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Baichuan-7B"
  model_path: "/mxstorage/pde_ai/models/llm/Baichuan/Baichuan-7B"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
      --chat-template: chat_template/template_baichuan.jinja
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Baichuan2-7B-Chat"
  model_path: "/mxstorage/pde_ai/models/llm/Baichuan/Baichuan2-7B-Chat"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
      --chat-template: chat_template/template_baichuan.jinja
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "ChatGLM3-6B"
  model_path: "/mxstorage/pde_ai/models/llm/ChatGLM/chatglm3-6b"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "GLM-4-9B-Chat"
  model_path: "/mxstorage/pde_ai/models/llm/ChatGLM/glm-4-9b-chat"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
      --chat-template: chat_template/template_chatglm.jinja
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "GLM-4v-9B"
  model_path: "/mxstorage/pde_ai/models/llm/ChatGLM/glm-4v-9b"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
      --hf-overrides: "'{\"architectures\": [\"GLM4VForCausalLM\"]}'"
      --chat-template: chat_template/template_chatglm.jinja
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "InternVL2_5-8B"
  model_path: "/mxstorage/pde_ai/models/llm/Internlm/InternVL2_5-8B"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    distributed_executor_backend: "mp"
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "internlm3-8b-instruct"
  model_path: "/mxstorage/pde_ai/models/llm/Internlm/internlm3-8b-instruct"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "InternVL2-8B"
  model_path: "/mxstorage/pde_ai/models/llm/Internlm/InternVL2-8B"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    distributed_executor_backend: "mp"
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Llama-2-7B-hf"
  model_path: "/mxstorage/pde_ai/models/llm/Llama/Llama-2-7b-hf"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:


- name: "Qwen2.5-VL-7B-Instruct"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen2.5-VL-7B-Instruct"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen2-VL-7B-Instruct"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen2-VL-7B-Instruct"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen2.5-72B-Instruct-AWQ"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen2___5-72B-Instruct-AWQ"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen2.5-72B-Instruct-GPTQ"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen2___5-72B-Instruct-GPTQ-Int4"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen2.5-14B-W8A8"
  model_path: "/mxstorage/pde_ai/models/llm/W8A8/Qwen2.5-14B-Instruct-W8A8-Dynamic-Per-Token"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen3-14B-AWQ"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-14B-AWQ"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen3-14B"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-14B"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen3-30B-A3B-W8A8"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-30B-A3B.w8a8"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen3-30B-A3B-AWQ"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-30B-A3B-AWQ"
  serve_config:
    tp: 2
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen3-4B"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-4B"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen3-8B"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-8B"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen3-1.7B"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-1___7B"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen3-VL-8B-Instruct"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-VL-8B-Instruct"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: Qwen3-VL-30B-A3B-Instruct_W8A8
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-VL-30B-A3B-Instruct_W8A8/vllm_quant_model"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name : "Qwen3-VL-4B-Instruct"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-VL-4B-Instruct"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen3-VL-8B-Instruct"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-VL-8B-Instruct"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen3-0.6B"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-0.6B"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen2.5-1.5B-Instruct"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen2___5-1___5B-Instruct"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen3-Reranker-8B"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-Reranker-8B"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Hunyuan-0.5B-Instruct"
  model_path: "/mxstorage/pde_ai/models/llm/Hunyuan/Hunyuan-0.5B-Instruct"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Hunyuan-7B-Instruct"
  model_path: "/mxstorage/pde_ai/models/llm/Hunyuan/Hunyuan-7B-Instruct"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "PaddleOCR-VL"
  model_path: "/mxstorage/pde_ai/models/llm/PaddleOCR-VL"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    is_multimodal: true
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "glm-4.6V"
  model_path: "/mxstorage/pde_ai/models/llm/ChatGLM/GLM-4.6V"
  serve_config:
    tp: 1
    dp: 1
    pp: 1
    is_multimodal: true
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen2-72B-Instruct-w8a8"
  model_path: "/mxstorage/pde_ai/models/llm/W8A8/Qwen2-72B-Instruct-quantized___w8a8"
  serve_config:
    tp: 2
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen3-30B-A3B"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-30B-A3B"
  serve_config:
    tp: 2
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen3-32B"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-32B"
  serve_config:
    tp: 2
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen3-Next-80B-A3B-Instruct.w8a8"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-Next-80B-A3B-Instruct.w8a8"
  serve_config:
    tp: 2
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen3-Omni-30B-A3B-Instruct"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-Omni-30B-A3B-Instruct"
  serve_config:
    tp: 2
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen3-VL-30B-A3B-Instruct"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-VL-30B-A3B-Instruct"
  serve_config:
    tp: 2
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Meta-Llama-3-70B-Instruct-w8a8"
  model_path: "/mxstorage/pde_ai/models/llm/W8A8/Meta-Llama-3-70B-Instruct-quantized___w8a8"
  serve_config:
    tp: 2
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "ERNIE-4.5-21B-A3B-PT"
  model_path: "/mxstorage/pde_ai/models/llm/ERNIE/ERNIE-4.5-21B-A3B-PT"
  serve_config:
    tp: 2
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "InternVL2_5-26B"
  model_path: "/mxstorage/pde_ai/models/llm/Internlm/InternVL2_5-26B"
  serve_config:
    tp: 2
    dp: 1
    pp: 1
    distributed_executor_backend: "mp"
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "internlm3-8b-instruct"
  model_path: "/mxstorage/pde_ai/models/llm/Internlm/internlm3-8b-instruct"
  serve_config:
    tp: 2
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Kimi-Linear-48B-A3B-Instruct"
  model_path: "/mxstorage/pde_ai/models/llm/Kimi-Linear-48B-A3B-Instruct"
  serve_config:
    tp: 2
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "GLM-4.6-W8A8"
  model_path: "/mxstorage/pde_ai/models/llm/ChatGLM/GLM-4.6-W8A8"
  serve_config:
    tp: 2
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "GLM-4.5V_W8A8"
  model_path: "/mxstorage/pde_ai/models/llm/ChatGLM/GLM-4.5V_W8A8/vllm_quant_model"
  serve_config:
    tp: 2
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Mistral-8x7B-v0.1"
  model_path: "/mxstorage/pde_ai/models/llm/Mistral/Mixtral-8x7B-v0.1"
  serve_config:
    tp: 4
    dp: 1
    pp: 1
    extra_args:
      --chat-template: chat_template/tool_chat_template_mistral.jinja
      --enable-auto-tool-choice:
      --tool-call-parser: "mistral"
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "QwQ-32B"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/QwQ-32B"
  serve_config:
    tp: 4
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen2.5-72B-Instruct"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen2.5-72B-Instruct"
  serve_config:
    tp: 4
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen3-32B"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-32B"
  serve_config:
    tp: 4
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:


- name: "Qwen3-Next-80B-A3B-Instruct.w8a8"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-Next-80B-A3B-Instruct.w8a8"
  serve_config:
    tp: 4
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen3-Next-80B-A3B-Instruct"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-Next-80B-A3B-Instruct"
  serve_config:
    tp: 4
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "DeepSeek-R1-Distill-Llama-70B"
  model_path: "/mxstorage/pde_ai/models/llm/DeepSeek/DeepSeek-R1-Distill-Llama-70B"
  serve_config:
    tp: 4
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "DeepSeek-R1-Distill-Qwen-32B"
  model_path: "/mxstorage/pde_ai/models/llm/DeepSeek/DeepSeek-R1-Distill-Qwen-32B"
  serve_config:
    tp: 4
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Meta-Llama-3-70B"
  model_path: "/mxstorage/pde_ai/models/llm/Llama/Meta-Llama-3-70B"
  serve_config:
    tp: 4
    dp: 1
    pp: 1
    extra_args:
      --chat-template: chat_template/tool_chat_template_llama3.1_json.jinja
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen3-30B-A3B"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-30B-A3B"
  serve_config:
    tp: 2
    dp: 2
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen3-32B"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-32B"
  serve_config:
    tp: 2
    dp: 2
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "DeepSeek-R1-Distill-Llama-70B"
  model_path: "/mxstorage/pde_ai/models/llm/DeepSeek/DeepSeek-R1-Distill-Llama-70B"
  serve_config:
    tp: 8
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "DeepSeek-R1-Distill-Qwen-32B"
  model_path: "/mxstorage/pde_ai/models/llm/DeepSeek/DeepSeek-R1-Distill-Qwen-32B"
  serve_config:
    tp: 8
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "DeepSeek-R1-L12-BF16"
  model_path: "/mxstorage/pde_ai/models/llm/DeepSeek/DeepSeek-R1-L12-BF16"
  serve_config:
    tp: 8
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "DeepSeek-R1-awq"
  model_path: "/mxstorage/pde_ai/models/llm/DeepSeek/DeepSeek-R1-awq"
  serve_config:
    tp: 8
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "DeepSeek-R1-BF16-L4-W8A8"
  model_path: "/mxstorage/pde_ai/models/llm/DeepSeek/DeepSeek-R1-BF16-L4-W8A8"
  serve_config:
    tp: 4
    dp: 2
    pp: 1
    # dcp: 2
    gpu_memory_utilization: 0.8
    extra_args:
  infer_type:
    - text-only
  benchmark:
      bench_param: "configs/bench_params/bench_default.json"
      sweep_num_runs: 1
  extra_env:

- name: "DeepSeek-R1-BF16-L4-W8A8"
  model_path: "/mxstorage/pde_ai/models/llm/DeepSeek/DeepSeek-R1-BF16-L4-W8A8"
  serve_config:
    tp: 4
    dp: 2
    pp: 1
    dcp: 2
    gpu_memory_utilization: 0.8
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen2.5-72B-Instruct"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen2.5-72B-Instruct"
  serve_config:
    tp: 8
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen3-235B-A22B-w8a8"
  timeout: 1200
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-235B-A22B.w8a8"
  serve_config:
    tp: 8
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:
  
- name: "QwQ-32B-Preview"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/QwQ-32B"
  serve_config:
    tp: 8
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen3-Next-80B-A3B-Instruct"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-Next-80B-A3B-Instruct"
  serve_config:
    tp: 8
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen2.5-VL-72B-Instruct"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen2.5-VL-72B-Instruct"
  serve_config:
    tp: 8
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Qwen3-VL-235B-A22B-Instruct_W8A8"
  model_path: "/mxstorage/pde_ai/models/llm/Qwen/Qwen3-VL-235B-A22B-Instruct_W8A8/vllm_quant_model"
  timeout: 1200
  serve_config:
    tp: 8
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "InternVL3-78B"
  model_path: "/mxstorage/pde_ai/models/llm/Internlm/InternVL3-78B"
  serve_config:
    tp: 8
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:

- name: "Mixtral-8x22B-Instruct-v0.1"
  model_path: "/mxstorage/pde_ai/models/llm/Mistral/Mixtral-8x22B-Instruct-v0.1"
  serve_config:
    tp: 8
    dp: 1
    pp: 1
    extra_args:
  infer_type:
    - text-only
  benchmark:
    bench_param: "configs/bench_params/bench_default.json"
    sweep_num_runs: 1
  extra_env:
